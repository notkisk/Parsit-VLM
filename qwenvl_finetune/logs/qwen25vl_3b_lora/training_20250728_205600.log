[2025-07-28 20:56:00] [    INFO] [root:73] Logging to file: ./logs/qwen25vl_3b_lora/training_20250728_205600.log
[2025-07-28 20:56:00] [    INFO] [__main__:49] Starting Qwen2.5-VL fine-tuning
[2025-07-28 20:56:00] [    INFO] [__main__:52] Loading 3B model...
[2025-07-28 20:56:00] [    INFO] [qwen25vl.models.model_utils:191] Loading 3B model: Qwen/Qwen2.5-VL-3B-Instruct
[2025-07-28 20:56:00] [    INFO] [qwen25vl.models.model_utils:200] Using 4-bit quantization
[2025-07-28 20:56:00] [    INFO] [qwen25vl.models.qwen25vl_model:65] Loading Qwen2.5-VL model: Qwen/Qwen2.5-VL-3B-Instruct
[2025-07-28 20:56:01] [    INFO] [accelerate.utils.modeling:1004] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-07-28 20:56:12] [    INFO] [qwen25vl.models.qwen25vl_model:89] Model loaded successfully. Parameters: {'total': 2034024448, 'trainable': 312902912, 'non_trainable': 1721121536, 'trainable_percentage': 15.383439088338823}
[2025-07-28 20:56:12] [    INFO] [qwen25vl.models.model_utils:221] Using custom LoRA configuration
[2025-07-28 20:56:12] [    INFO] [qwen25vl.models.model_utils:148] Applying LoRA configuration to model
[2025-07-28 20:56:12] [    INFO] [qwen25vl.models.qwen25vl_model:128] Applying LoRA with config: {'enabled': True, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'bias': 'none', 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], 'inference_mode': False, 'use_rslora': False, 'use_dora': False}
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.qwen25vl_model:135] LoRA applied. Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.model_utils:229] Model loaded successfully:
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.model_utils:230]   Total parameters: 2,076,104,704
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.model_utils:231]   Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.model_utils:232]   Memory footprint: 2399.2 MB
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:352] DataProcessor initialized
[2025-07-28 20:56:13] [    INFO] [__main__:88] Loading training data...
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.conversation:53] ConversationHandler initialized with template: chatml
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:72] Loaded 10 samples for train split
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:451] Analyzing dataset...
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:493] Dataset analysis complete:
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:494]   Total samples: 10
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:495]   Average conversation length: 6.8
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.data_processor:496]   Multimodal samples: 10 (100.0%)
[2025-07-28 20:56:13] [    INFO] [__main__:93] Dataset loaded: 10 samples
[2025-07-28 20:56:13] [    INFO] [qwen25vl.models.qwen25vl_model:244] Gradient checkpointing enabled
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:120] Gradient checkpointing enabled
[2025-07-28 20:56:13] [    INFO] [qwen25vl.utils.memory_utils:71] Memory caches cleared
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:237] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:238] MODEL PARAMETER SUMMARY
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:239] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:240] Total parameters: 2,076,104,704
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:241] Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:242] Frozen parameters: 2,034,024,448 (97.97%)
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:243] 
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:244] Parameters by layer:
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:248]   base_model: 2,076,104,704 total, 42,080,256 trainable (2.0%)
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:250] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:109] Qwen25VLTrainer initialized successfully
[2025-07-28 20:56:13] [    INFO] [__main__:111] Starting training...
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:274] Starting Qwen2.5-VL training...
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:256] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:257] TRAINING CONFIGURATION
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:258] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] gradient_accumulation_steps: 4
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] gradient_checkpointing: True
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] learning_rate: 0.0003
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] lr_scheduler_type: SchedulerType.COSINE
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] model_size: 3B
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] num_train_epochs: 5
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] per_device_train_batch_size: 1
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] use_deepspeed: True
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] use_lora: False
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] warmup_ratio: 0.05
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:266] weight_decay: 0.01
[2025-07-28 20:56:13] [    INFO] [qwen25vl.training.trainer:268] ============================================================
[2025-07-28 20:56:13] [    INFO] [qwen25vl_trainer:203] Initial: GPU 0 (NVIDIA RTX A4500): Allocated: 2.39GB | Reserved: 2.52GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.2%
[2025-07-28 20:56:14] [    INFO] [qwen25vl.models.qwen25vl_model:255] Gradient checkpointing enabled
[2025-07-28 20:56:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:14] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.39GB | Reserved: 2.52GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.2%
[2025-07-28 20:56:15] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 0.00 steps/s | ETA: 0.0h
[2025-07-28 20:56:15] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 2.94GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:56:15] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 1.86 steps/s | ETA: 0.0h
[2025-07-28 20:56:15] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 3.01GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:56:16] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 2.03 steps/s | ETA: 0.0h
[2025-07-28 20:56:16] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 3.01GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:56:16] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 1.95 steps/s | ETA: 0.0h
[2025-07-28 20:56:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:17] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:20] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:20] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:20] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:20] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:20] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:22] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:22] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:22] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:22] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:25] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:25] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:25] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:25] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:25] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:27] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:27] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:27] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:27] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:30] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:30] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:30] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:30] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:30] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:32] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:32] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:32] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:32] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:34] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:35] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:35] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:35] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:35] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:35] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:37] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:37] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:37] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:37] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:39] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:56:40] [    INFO] [qwen25vl.training.trainer:196] Saving checkpoint at step 15
[2025-07-28 20:56:40] [   ERROR] [qwen25vl.training.trainer:313] Training failed with error: 
            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.base_model.model.model.language_model.embed_tokens.base_layer.weight', 'model.base_model.model.lm_head.base_layer.weight'}].
            A potential way to correctly save your model is to use `save_model`.
            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors
            
[2025-07-28 20:56:40] [    INFO] [qwen25vl.utils.memory_utils:71] Memory caches cleared
