[2025-07-28 20:58:55] [    INFO] [root:73] Logging to file: ./logs/qwen25vl_3b_lora/training_20250728_205855.log
[2025-07-28 20:58:55] [    INFO] [__main__:49] Starting Qwen2.5-VL fine-tuning
[2025-07-28 20:58:55] [    INFO] [__main__:52] Loading 3B model...
[2025-07-28 20:58:55] [    INFO] [qwen25vl.models.model_utils:191] Loading 3B model: Qwen/Qwen2.5-VL-3B-Instruct
[2025-07-28 20:58:55] [    INFO] [qwen25vl.models.model_utils:200] Using 4-bit quantization
[2025-07-28 20:58:55] [    INFO] [qwen25vl.models.qwen25vl_model:65] Loading Qwen2.5-VL model: Qwen/Qwen2.5-VL-3B-Instruct
[2025-07-28 20:58:56] [    INFO] [accelerate.utils.modeling:1004] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-07-28 20:59:07] [    INFO] [qwen25vl.models.qwen25vl_model:89] Model loaded successfully. Parameters: {'total': 2034024448, 'trainable': 312902912, 'non_trainable': 1721121536, 'trainable_percentage': 15.383439088338823}
[2025-07-28 20:59:07] [    INFO] [qwen25vl.models.model_utils:221] Using custom LoRA configuration
[2025-07-28 20:59:07] [    INFO] [qwen25vl.models.model_utils:148] Applying LoRA configuration to model
[2025-07-28 20:59:07] [    INFO] [qwen25vl.models.qwen25vl_model:128] Applying LoRA with config: {'enabled': True, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'bias': 'none', 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], 'inference_mode': False, 'use_rslora': False, 'use_dora': False}
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.qwen25vl_model:135] LoRA applied. Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.model_utils:229] Model loaded successfully:
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.model_utils:230]   Total parameters: 2,076,104,704
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.model_utils:231]   Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.model_utils:232]   Memory footprint: 2399.2 MB
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:352] DataProcessor initialized
[2025-07-28 20:59:08] [    INFO] [__main__:88] Loading training data...
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.conversation:53] ConversationHandler initialized with template: chatml
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:72] Loaded 10 samples for train split
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:451] Analyzing dataset...
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:493] Dataset analysis complete:
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:494]   Total samples: 10
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:495]   Average conversation length: 6.8
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.data_processor:496]   Multimodal samples: 10 (100.0%)
[2025-07-28 20:59:08] [    INFO] [__main__:93] Dataset loaded: 10 samples
[2025-07-28 20:59:08] [    INFO] [qwen25vl.models.qwen25vl_model:244] Gradient checkpointing enabled
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:120] Gradient checkpointing enabled
[2025-07-28 20:59:08] [    INFO] [qwen25vl.utils.memory_utils:71] Memory caches cleared
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:237] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:238] MODEL PARAMETER SUMMARY
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:239] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:240] Total parameters: 2,076,104,704
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:241] Trainable parameters: 42,080,256 (2.03%)
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:242] Frozen parameters: 2,034,024,448 (97.97%)
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:243] 
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:244] Parameters by layer:
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:248]   base_model: 2,076,104,704 total, 42,080,256 trainable (2.0%)
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:250] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:109] Qwen25VLTrainer initialized successfully
[2025-07-28 20:59:08] [    INFO] [__main__:111] Starting training...
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:288] Starting Qwen2.5-VL training...
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:256] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:257] TRAINING CONFIGURATION
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:258] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] gradient_accumulation_steps: 4
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] gradient_checkpointing: True
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] learning_rate: 0.0003
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] lr_scheduler_type: SchedulerType.COSINE
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] model_size: 3B
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] num_train_epochs: 5
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] per_device_train_batch_size: 1
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] use_deepspeed: True
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] use_lora: False
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] warmup_ratio: 0.05
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:266] weight_decay: 0.01
[2025-07-28 20:59:08] [    INFO] [qwen25vl.training.trainer:268] ============================================================
[2025-07-28 20:59:08] [    INFO] [qwen25vl_trainer:203] Initial: GPU 0 (NVIDIA RTX A4500): Allocated: 2.39GB | Reserved: 2.52GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.2%
[2025-07-28 20:59:09] [    INFO] [qwen25vl.models.qwen25vl_model:255] Gradient checkpointing enabled
[2025-07-28 20:59:09] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:09] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:09] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:09] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:09] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:09] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.39GB | Reserved: 2.52GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.2%
[2025-07-28 20:59:10] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 0.00 steps/s | ETA: 0.0h
[2025-07-28 20:59:10] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 2.94GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:59:10] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 1.92 steps/s | ETA: 0.0h
[2025-07-28 20:59:10] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 3.01GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:59:11] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 2.07 steps/s | ETA: 0.0h
[2025-07-28 20:59:11] [    INFO] [qwen25vl_trainer:203] Step 0 - Before forward: GPU 0 (NVIDIA RTX A4500): Allocated: 2.54GB | Reserved: 3.01GB | Max Allocated: 3.50GB | Total: 19.70GB | Utilization: 12.9%
[2025-07-28 20:59:11] [    INFO] [qwen25vl_trainer:139] Step      0/15 (  0.0%) | Loss: nan | LR: 0.00e+00 | Speed: 2.06 steps/s | ETA: 0.0h
[2025-07-28 20:59:11] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:11] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:11] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:11] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:13] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:14] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:16] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:18] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:19] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:21] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:21] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:21] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:21] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:23] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:24] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:26] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:26] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:26] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:26] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:28] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:29] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:31] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:31] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:31] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:31] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:33] [ WARNING] [qwen25vl.training.conversation:290] Processor failed, falling back to tokenizer: index 1 is out of bounds for dimension 0 with size 1
[2025-07-28 20:59:34] [    INFO] [qwen25vl.training.trainer:196] Saving checkpoint at step 15
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:219] LoRA checkpoint saved to ./checkpoints/qwen25vl_3b_finetune/checkpoint-15
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:316] Training completed successfully!
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:320] Training Summary:
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:322]   total_steps: 4
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:322]   latest_loss: nan
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:322]   avg_recent_loss: nan
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:322]   avg_steps_per_sec: 1.5134725366063688
[2025-07-28 20:59:38] [    INFO] [qwen25vl.training.trainer:322]   total_training_time_hours: 0.008312951591279772
[2025-07-28 20:59:38] [    INFO] [qwen25vl.utils.memory_utils:71] Memory caches cleared
[2025-07-28 20:59:38] [    INFO] [__main__:115] Saving final model...
